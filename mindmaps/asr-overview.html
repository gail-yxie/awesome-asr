<!doctype html>
<html>
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
html {
  font-family: ui-sans-serif, system-ui, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.markmap-dark {
  background: #27272a;
  color: white;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.18.12/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/index.js"></script><script>((r) => {
          setTimeout(r);
        })(() => {
  const { markmap, mm } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute("style", "position:absolute;bottom:20px;right:20px");
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
              const markmap = getMarkmap();
              window.mm = markmap.Markmap.create(
                "svg#mindmap",
                (getOptions || markmap.deriveOptions)(jsonOptions),
                root2
              );
              if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
                document.documentElement.classList.add("markmap-dark");
              }
            })(() => window.markmap,null,{"content":"","children":[{"content":"Automatic Speech Recognition","children":[{"content":"Architectures","children":[{"content":"CTC-based","children":[{"content":"wav2vec 2.0","children":[],"payload":{"tag":"li","lines":"3,4"}},{"content":"Conformer-CTC","children":[],"payload":{"tag":"li","lines":"4,5"}},{"content":"Deep Speech","children":[],"payload":{"tag":"li","lines":"5,6"}},{"content":"saidaAo/wav2vec2-base-librispeech-demo","children":[],"payload":{"tag":"li","lines":"6,8"}}],"payload":{"tag":"h3","lines":"2,3"}},{"content":"Attention-based","children":[{"content":"Whisper","children":[],"payload":{"tag":"li","lines":"9,10"}},{"content":"LAS","children":[],"payload":{"tag":"li","lines":"10,11"}},{"content":"Speech-Transformer","children":[],"payload":{"tag":"li","lines":"11,12"}},{"content":"fiendshadow/whisper-large-v3","children":[],"payload":{"tag":"li","lines":"12,13"}},{"content":"Kush0610/whisper-medium-hi-uncurated-reverse-mft-1","children":[],"payload":{"tag":"li","lines":"13,14"}},{"content":"MinaNasser/whisper-base-arabic","children":[],"payload":{"tag":"li","lines":"14,15"}},{"content":"dmartu/VibeVoice-ASR-HFI","children":[],"payload":{"tag":"li","lines":"15,16"}},{"content":"dianavdavidson/wh_l_v3_turbo_mucs_no_langid_mucs_48419_trial","children":[],"payload":{"tag":"li","lines":"16,17"}},{"content":"lewiswoncy/m_test_10","children":[],"payload":{"tag":"li","lines":"17,18"}},{"content":"lewiswoncy/m_test_8","children":[],"payload":{"tag":"li","lines":"18,19"}},{"content":"7ocho/WMAC1","children":[],"payload":{"tag":"li","lines":"19,20"}},{"content":"7ocho/WMAC","children":[],"payload":{"tag":"li","lines":"20,22"}}],"payload":{"tag":"h3","lines":"8,9"}},{"content":"Transducer","children":[{"content":"RNN-T","children":[],"payload":{"tag":"li","lines":"23,24"}},{"content":"Conformer-Transducer","children":[],"payload":{"tag":"li","lines":"24,25"}},{"content":"Parakeet-TDT (Token-and-Duration Transducer)","children":[],"payload":{"tag":"li","lines":"25,26"}},{"content":"nvidia/parakeet-tdt-0.6b-v2","children":[],"payload":{"tag":"li","lines":"26,28"}}],"payload":{"tag":"h3","lines":"22,23"}},{"content":"Foundation Models","children":[{"content":"USM","children":[],"payload":{"tag":"li","lines":"29,30"}},{"content":"SeamlessM4T","children":[],"payload":{"tag":"li","lines":"30,31"}},{"content":"MMS","children":[],"payload":{"tag":"li","lines":"31,32"}},{"content":"W2v-BERT 2.0","children":[],"payload":{"tag":"li","lines":"32,33"}},{"content":"XLS-R","children":[],"payload":{"tag":"li","lines":"33,34"}},{"content":"vitthalbhandari/mms-1b-all-aft-all-meh","children":[],"payload":{"tag":"li","lines":"34,35"}},{"content":"vitthalbhandari/mms-1b-all-aft-all-lke","children":[],"payload":{"tag":"li","lines":"35,36"}},{"content":"Professor/mms-300m-fongbe","children":[],"payload":{"tag":"li","lines":"36,38"}}],"payload":{"tag":"h3","lines":"28,29"}},{"content":"LLM-based ASR","children":[{"content":"Jonxxxxxx/Qwen3-ASR-0.6B","children":[],"payload":{"tag":"li","lines":"39,40"}},{"content":"Kushtrim/Qwen3-ASR-0.6B-Albanian-728h","children":[],"payload":{"tag":"li","lines":"40,43"}}],"payload":{"tag":"h3","lines":"38,39"}}],"payload":{"tag":"h2","lines":"1,2"}},{"content":"Self-Supervised Learning","children":[{"content":"Contrastive","children":[{"content":"wav2vec 2.0","children":[],"payload":{"tag":"li","lines":"45,46"}},{"content":"WavLM","children":[],"payload":{"tag":"li","lines":"46,48"}}],"payload":{"tag":"h3","lines":"44,45"}},{"content":"Masked Prediction","children":[{"content":"HuBERT","children":[],"payload":{"tag":"li","lines":"49,50"}},{"content":"data2vec","children":[],"payload":{"tag":"li","lines":"50,52"}}],"payload":{"tag":"h3","lines":"48,49"}},{"content":"Multi-task","children":[{"content":"W2v-BERT","children":[],"payload":{"tag":"li","lines":"53,54"}},{"content":"ctaguchi/w2v-bert-2.0-gui","children":[],"payload":{"tag":"li","lines":"54,55"}},{"content":"abidanoaman/urdu-asr-xlsr53-finetuned","children":[],"payload":{"tag":"li","lines":"55,58"}}],"payload":{"tag":"h3","lines":"52,53"}}],"payload":{"tag":"h2","lines":"43,44"}},{"content":"Tasks","children":[{"content":"Transcription","children":[{"content":"Real-time","children":[],"payload":{"tag":"li","lines":"60,61"}},{"content":"Offline","children":[],"payload":{"tag":"li","lines":"61,62"}},{"content":"Long-form","children":[],"payload":{"tag":"li","lines":"62,64"}}],"payload":{"tag":"h3","lines":"59,60"}},{"content":"Speaker Diarization","children":[{"content":"Make It Hard to Hear, Easy to Learn: Long-Form Bengali ASR and Speaker Diarization","children":[],"payload":{"tag":"li","lines":"65,66"}},{"content":"A Holistic Framework for Robust Bangla ASR and Speaker Diarization","children":[],"payload":{"tag":"li","lines":"66,67"}},{"content":"Robust Long-Form Bangla Speech Processing","children":[],"payload":{"tag":"li","lines":"67,68"}},{"content":"823-OLT @ BUET DL Sprint 4.0: Context-Aware Windowing and Fine-Tuned Diarization","children":[],"payload":{"tag":"li","lines":"68,70"}}],"payload":{"tag":"h3","lines":"64,65"}},{"content":"Multilingual","children":[{"content":"Code-switching","children":[],"payload":{"tag":"li","lines":"71,72"}},{"content":"Low-resource","children":[],"payload":{"tag":"li","lines":"72,73"}},{"content":"Cross-lingual","children":[],"payload":{"tag":"li","lines":"73,74"}},{"content":"Dialect-Aware Modeling (Hakka)","children":[],"payload":{"tag":"li","lines":"74,75"}},{"content":"TG-ASR: Translation-Guided Learning","children":[],"payload":{"tag":"li","lines":"75,76"}},{"content":"AWARRITech/whisper-small-yoruba-v1","children":[],"payload":{"tag":"li","lines":"76,77"}},{"content":"DewiBrynJones/whisper-large-v2-ft-cy-2601","children":[],"payload":{"tag":"li","lines":"77,78"}},{"content":"afaqalinagra/whisper-base-ps","children":[],"payload":{"tag":"li","lines":"78,79"}},{"content":"Cong123779/AI2Text-Bilingual-ASR","children":[],"payload":{"tag":"li","lines":"79,80"}},{"content":"kesavamas/whisper-small-fleurs-id","children":[],"payload":{"tag":"li","lines":"80,81"}},{"content":"korir8/sauti-whisper-small-swh","children":[],"payload":{"tag":"li","lines":"81,82"}},{"content":"amanuelbyte/whisper-amharic-asr-finetuned","children":[],"payload":{"tag":"li","lines":"82,84"}}],"payload":{"tag":"h3","lines":"70,71"}},{"content":"Multimodal","children":[{"content":"Audio-Visual ASR","children":[],"payload":{"tag":"li","lines":"85,86"}},{"content":"Speech Translation","children":[],"payload":{"tag":"li","lines":"86,87"}},{"content":"CLAP-Based Recognition","children":[],"payload":{"tag":"li","lines":"87,88"}},{"content":"Multimodal Emotion Recognition in Conversations (Mixture-of-Experts)","children":[],"payload":{"tag":"li","lines":"88,89"}},{"content":"Scalable Multilingual Multimodal Machine Translation with Speech-Text Fusion","children":[],"payload":{"tag":"li","lines":"89,91"}}],"payload":{"tag":"h3","lines":"84,85"}},{"content":"Specialized","children":[{"content":"Medical Transcription","children":[],"payload":{"tag":"li","lines":"92,93"}},{"content":"Meeting Transcription","children":[],"payload":{"tag":"li","lines":"93,94"}},{"content":"Call Center","children":[],"payload":{"tag":"li","lines":"94,95"}},{"content":"Disordered Speech Recognition (Aphasia, Impaired Speech)","children":[],"payload":{"tag":"li","lines":"95,96"}},{"content":"Word Naming Recognition","children":[],"payload":{"tag":"li","lines":"96,97"}},{"content":"gabrielbuzzi/medasr-public","children":[],"payload":{"tag":"li","lines":"97,98"}},{"content":"Phonetic Transcription (IPA)","children":[],"payload":{"tag":"li","lines":"98,99"}},{"content":"neurlang/ipa-whisper-medium","children":[],"payload":{"tag":"li","lines":"99,100"}},{"content":"Religious/Liturgical Speech","children":[],"payload":{"tag":"li","lines":"100,101"}},{"content":"9DTechnologies/QuartzNet_quran_v1","children":[],"payload":{"tag":"li","lines":"101,102"}},{"content":"wasimlhr/whisper-large-v3-Tarteel-even-g2","children":[],"payload":{"tag":"li","lines":"102,103"}},{"content":"CLAP-Based Automatic Word Naming Recognition in Post-Stroke Aphasia","children":[],"payload":{"tag":"li","lines":"103,106"}}],"payload":{"tag":"h3","lines":"91,92"}}],"payload":{"tag":"h2","lines":"58,59"}},{"content":"Datasets","children":[{"content":"English","children":[{"content":"LibriSpeech","children":[],"payload":{"tag":"li","lines":"108,109"}},{"content":"Common Voice","children":[],"payload":{"tag":"li","lines":"109,110"}},{"content":"GigaSpeech","children":[],"payload":{"tag":"li","lines":"110,111"}},{"content":"SPGISpeech","children":[],"payload":{"tag":"li","lines":"111,113"}}],"payload":{"tag":"h3","lines":"107,108"}},{"content":"Multilingual","children":[{"content":"MLS","children":[],"payload":{"tag":"li","lines":"114,115"}},{"content":"FLEURS","children":[],"payload":{"tag":"li","lines":"115,116"}},{"content":"CoVoST","children":[],"payload":{"tag":"li","lines":"116,117"}},{"content":"VoxPopuli","children":[],"payload":{"tag":"li","lines":"117,118"}},{"content":"Pashto Common Voice (Scale Analysis)","children":[],"payload":{"tag":"li","lines":"118,119"}},{"content":"Akan Impaired Speech Dataset","children":[],"payload":{"tag":"li","lines":"119,121"}}],"payload":{"tag":"h3","lines":"113,114"}},{"content":"Benchmarks","children":[{"content":"ESB","children":[],"payload":{"tag":"li","lines":"122,123"}},{"content":"Open ASR Leaderboard","children":[],"payload":{"tag":"li","lines":"123,126"}}],"payload":{"tag":"h3","lines":"121,122"}}],"payload":{"tag":"h2","lines":"106,107"}},{"content":"Techniques","children":[{"content":"Data Augmentation","children":[{"content":"SpecAugment","children":[],"payload":{"tag":"li","lines":"128,129"}},{"content":"Speed Perturbation","children":[],"payload":{"tag":"li","lines":"129,130"}},{"content":"Noise Injection","children":[],"payload":{"tag":"li","lines":"130,131"}},{"content":"Extreme Augmentation for Long-Form Audio","children":[],"payload":{"tag":"li","lines":"131,133"}}],"payload":{"tag":"h3","lines":"127,128"}},{"content":"Decoding","children":[{"content":"Beam Search","children":[],"payload":{"tag":"li","lines":"134,135"}},{"content":"CTC Decoding","children":[],"payload":{"tag":"li","lines":"135,136"}},{"content":"Language Model Fusion","children":[],"payload":{"tag":"li","lines":"136,138"}}],"payload":{"tag":"h3","lines":"133,134"}},{"content":"Compression","children":[{"content":"Quantization","children":[],"payload":{"tag":"li","lines":"139,140"}},{"content":"Distillation","children":[],"payload":{"tag":"li","lines":"140,141"}},{"content":"Pruning","children":[],"payload":{"tag":"li","lines":"141,142"}},{"content":"RayOrz/whisperkit-coreml","children":[],"payload":{"tag":"li","lines":"142,143"}},{"content":"smkrv/whisper-podlodka-turbo-coreml","children":[],"payload":{"tag":"li","lines":"143,144"}},{"content":"kzmaker/faster-whisper-tilsync-34000","children":[],"payload":{"tag":"li","lines":"144,146"}}],"payload":{"tag":"h3","lines":"138,139"}},{"content":"Adaptation","children":[{"content":"Depth-Aware Adaptation","children":[],"payload":{"tag":"li","lines":"147,148"}},{"content":"Low-Rank Adaptation (LoRA)","children":[],"payload":{"tag":"li","lines":"148,149"}},{"content":"Fine-tuning","children":[],"payload":{"tag":"li","lines":"149,150"}},{"content":"maryamas222/whisper-large-v3-egyptian-lora-v4","children":[],"payload":{"tag":"li","lines":"150,152"}}],"payload":{"tag":"h3","lines":"146,147"}},{"content":"Post-processing","children":[{"content":"Punctuation Restoration","children":[],"payload":{"tag":"li","lines":"153,154"}},{"content":"Structural Noise Mitigation in S2TT","children":[],"payload":{"tag":"li","lines":"154,157"}}],"payload":{"tag":"h3","lines":"152,153"}}],"payload":{"tag":"h2","lines":"126,127"}},{"content":"Evaluation","children":[{"content":"Metrics","children":[{"content":"WER","children":[],"payload":{"tag":"li","lines":"159,160"}},{"content":"CER","children":[],"payload":{"tag":"li","lines":"160,161"}},{"content":"RTF","children":[],"payload":{"tag":"li","lines":"161,162"}},{"content":"BLEU (for ST)","children":[],"payload":{"tag":"li","lines":"162,164"}}],"payload":{"tag":"h3","lines":"158,159"}},{"content":"Benchmarks","children":[{"content":"Open ASR Leaderboard","children":[],"payload":{"tag":"li","lines":"165,166"}},{"content":"ESB","children":[],"payload":{"tag":"li","lines":"166,167"}},{"content":"SUPERB","children":[],"payload":{"tag":"li","lines":"167,170"}}],"payload":{"tag":"h3","lines":"164,165"}}],"payload":{"tag":"h2","lines":"157,158"}},{"content":"Applications","children":[{"content":"Voice Assistants","children":[],"payload":{"tag":"h3","lines":"171,172"}},{"content":"Accessibility","children":[{"content":"Captioning","children":[],"payload":{"tag":"li","lines":"174,175"}},{"content":"Hearing Aid","children":[],"payload":{"tag":"li","lines":"175,176"}},{"content":"Aphasia Support Tools","children":[],"payload":{"tag":"li","lines":"176,178"}}],"payload":{"tag":"h3","lines":"173,174"}},{"content":"Content Creation","children":[{"content":"Podcasting","children":[],"payload":{"tag":"li","lines":"179,180"}},{"content":"Subtitling","children":[],"payload":{"tag":"li","lines":"180,182"}}],"payload":{"tag":"h3","lines":"178,179"}},{"content":"Enterprise","children":[{"content":"Call Analytics","children":[],"payload":{"tag":"li","lines":"183,184"}},{"content":"Meeting Notes","children":[],"payload":{"tag":"li","lines":"184,186"}}],"payload":{"tag":"h3","lines":"182,183"}},{"content":"Edge &amp; Robotics","children":[{"content":"UAV-Assisted Emergency Networks","children":[],"payload":{"tag":"li","lines":"187,188"}},{"content":"Voice-Driven Semantic Perception","children":[],"payload":{"tag":"li","lines":"188,192"}}],"payload":{"tag":"h3","lines":"186,187"}}],"payload":{"tag":"h2","lines":"170,171"}}],"payload":{"tag":"h1","lines":"0,1"}},{"content":"Speech Language Models","children":[{"content":"Architectures","children":[{"content":"Encoder-Decoder SLMs","children":[{"content":"AudioPaLM","children":[],"payload":{"tag":"li","lines":"195,196"}},{"content":"SpeechGPT","children":[],"payload":{"tag":"li","lines":"196,197"}},{"content":"LauraGPT","children":[],"payload":{"tag":"li","lines":"197,199"}}],"payload":{"tag":"h3","lines":"194,195"}},{"content":"Decoder-only SLMs","children":[{"content":"GSLM","children":[],"payload":{"tag":"li","lines":"200,201"}},{"content":"Spirit-LM","children":[],"payload":{"tag":"li","lines":"201,202"}},{"content":"Moshi","children":[],"payload":{"tag":"li","lines":"202,203"}},{"content":"VoxtLM","children":[],"payload":{"tag":"li","lines":"203,205"}}],"payload":{"tag":"h3","lines":"199,200"}},{"content":"Codec-based","children":[{"content":"VALL-E","children":[],"payload":{"tag":"li","lines":"206,207"}},{"content":"SoundStorm","children":[],"payload":{"tag":"li","lines":"207,208"}},{"content":"MusicGen","children":[],"payload":{"tag":"li","lines":"208,211"}}],"payload":{"tag":"h3","lines":"205,206"}}],"payload":{"tag":"h2","lines":"193,194"}},{"content":"Speech Tokenization","children":[{"content":"Semantic Tokens","children":[{"content":"HuBERT k-means","children":[],"payload":{"tag":"li","lines":"213,214"}},{"content":"SpeechTokenizer","children":[],"payload":{"tag":"li","lines":"214,215"}},{"content":"WavTokenizer","children":[],"payload":{"tag":"li","lines":"215,216"}},{"content":"Mimi1782/KMEANS","children":[],"payload":{"tag":"li","lines":"216,218"}}],"payload":{"tag":"h3","lines":"212,213"}},{"content":"Acoustic Tokens","children":[{"content":"EnCodec","children":[],"payload":{"tag":"li","lines":"219,220"}},{"content":"SoundStream","children":[],"payload":{"tag":"li","lines":"220,221"}},{"content":"DAC","children":[],"payload":{"tag":"li","lines":"221,222"}},{"content":"Vocos","children":[],"payload":{"tag":"li","lines":"222,224"}}],"payload":{"tag":"h3","lines":"218,219"}},{"content":"Hybrid Approaches","children":[{"content":"Multi-codebook tokenization","children":[],"payload":{"tag":"li","lines":"225,226"}},{"content":"Semantic-acoustic fusion","children":[],"payload":{"tag":"li","lines":"226,227"}},{"content":"ZeroSyl: Zero-Resource Syllable Tokenization","children":[],"payload":{"tag":"li","lines":"227,230"}}],"payload":{"tag":"h3","lines":"224,225"}}],"payload":{"tag":"h2","lines":"211,212"}},{"content":"Text-to-Speech","children":[{"content":"Autoregressive TTS","children":[{"content":"VALL-E","children":[],"payload":{"tag":"li","lines":"232,233"}},{"content":"SPEAR-TTS","children":[],"payload":{"tag":"li","lines":"233,234"}},{"content":"CLaM-TTS","children":[],"payload":{"tag":"li","lines":"234,236"}}],"payload":{"tag":"h3","lines":"231,232"}},{"content":"Non-autoregressive TTS","children":[{"content":"VITS","children":[],"payload":{"tag":"li","lines":"237,238"}},{"content":"NaturalSpeech","children":[],"payload":{"tag":"li","lines":"238,239"}},{"content":"Matcha-TTS","children":[],"payload":{"tag":"li","lines":"239,241"}}],"payload":{"tag":"h3","lines":"236,237"}},{"content":"Diffusion-based TTS","children":[{"content":"Grad-TTS","children":[],"payload":{"tag":"li","lines":"242,243"}},{"content":"DiffSinger","children":[],"payload":{"tag":"li","lines":"243,245"}}],"payload":{"tag":"h3","lines":"241,242"}},{"content":"LLM-based TTS","children":[{"content":"CTC-TTS: Dual-streaming text-to-speech","children":[],"payload":{"tag":"li","lines":"246,249"}}],"payload":{"tag":"h3","lines":"245,246"}}],"payload":{"tag":"h2","lines":"230,231"}},{"content":"Speech Generation Tasks","children":[{"content":"Voice Cloning","children":[{"content":"Zero-shot voice cloning","children":[],"payload":{"tag":"li","lines":"251,252"}},{"content":"Few-shot adaptation","children":[],"payload":{"tag":"li","lines":"252,254"}}],"payload":{"tag":"h3","lines":"250,251"}},{"content":"Voice Conversion","children":[{"content":"Any-to-any VC","children":[],"payload":{"tag":"li","lines":"255,256"}},{"content":"Cross-lingual VC","children":[],"payload":{"tag":"li","lines":"256,258"}}],"payload":{"tag":"h3","lines":"254,255"}},{"content":"Speech-to-Speech","children":[{"content":"Direct translation","children":[],"payload":{"tag":"li","lines":"259,260"}},{"content":"Speech continuation","children":[],"payload":{"tag":"li","lines":"260,261"}},{"content":"Spoken dialogue","children":[],"payload":{"tag":"li","lines":"261,263"}}],"payload":{"tag":"h3","lines":"258,259"}},{"content":"Expressive Speech","children":[{"content":"Emotion control","children":[],"payload":{"tag":"li","lines":"264,265"}},{"content":"Prosody transfer","children":[],"payload":{"tag":"li","lines":"265,266"}},{"content":"Style transfer","children":[],"payload":{"tag":"li","lines":"266,269"}}],"payload":{"tag":"h3","lines":"263,264"}}],"payload":{"tag":"h2","lines":"249,250"}},{"content":"Training Approaches","children":[{"content":"Pre-training","children":[{"content":"Speech-text joint pre-training","children":[],"payload":{"tag":"li","lines":"271,272"}},{"content":"Next-token prediction on speech","children":[],"payload":{"tag":"li","lines":"272,273"}},{"content":"Masked speech modeling","children":[],"payload":{"tag":"li","lines":"273,275"}}],"payload":{"tag":"h3","lines":"270,271"}},{"content":"Alignment","children":[{"content":"Speech-text alignment","children":[],"payload":{"tag":"li","lines":"276,277"}},{"content":"Interleaved speech-text training","children":[],"payload":{"tag":"li","lines":"277,278"}},{"content":"Cross-lingual Matryoshka Representation Learning","children":[],"payload":{"tag":"li","lines":"278,279"}},{"content":"TADA: Text-Acoustic Dual Alignment","children":[],"payload":{"tag":"li","lines":"279,281"}}],"payload":{"tag":"h3","lines":"275,276"}},{"content":"Reinforcement Learning","children":[{"content":"RLHF for speech","children":[],"payload":{"tag":"li","lines":"282,283"}},{"content":"DPO for speech quality","children":[],"payload":{"tag":"li","lines":"283,286"}}],"payload":{"tag":"h3","lines":"281,282"}}],"payload":{"tag":"h2","lines":"269,270"}},{"content":"Evaluation","children":[{"content":"Metrics","children":[{"content":"MOS (Mean Opinion Score)","children":[],"payload":{"tag":"li","lines":"288,289"}},{"content":"PESQ","children":[],"payload":{"tag":"li","lines":"289,290"}},{"content":"UTMOS","children":[],"payload":{"tag":"li","lines":"290,291"}},{"content":"Speaker similarity","children":[],"payload":{"tag":"li","lines":"291,292"}},{"content":"Word Error Rate","children":[],"payload":{"tag":"li","lines":"292,294"}}],"payload":{"tag":"h3","lines":"287,288"}},{"content":"Benchmarks","children":[{"content":"SUPERB","children":[],"payload":{"tag":"li","lines":"295,296"}},{"content":"Dynamic-SUPERB","children":[],"payload":{"tag":"li","lines":"296,297"}},{"content":"AudioBench","children":[],"payload":{"tag":"li","lines":"297,300"}}],"payload":{"tag":"h3","lines":"294,295"}}],"payload":{"tag":"h2","lines":"286,287"}}],"payload":{"tag":"h1","lines":"192,193"}}]},null)</script>
</body>
</html>
