{
  "Automatic Speech Recognition": {
    "Architectures": {
      "CTC-based": [
        "wav2vec 2.0",
        "Conformer-CTC",
        "Deep Speech"
      ],
      "Attention-based": [
        "Whisper",
        "LAS",
        "Speech-Transformer",
        "Kush0610/whisper-medium-hi-uncurated-reverse-mft-1",
        "MinaNasser/whisper-base-arabic"
      ],
      "Transducer": [
        "RNN-T",
        "Conformer-Transducer",
        "Parakeet-TDT (Token-and-Duration Transducer)",
        "nvidia/parakeet-tdt-0.6b-v2"
      ],
      "Foundation Models": [
        "USM",
        "SeamlessM4T",
        "MMS",
        "W2v-BERT 2.0",
        "XLS-R"
      ]
    },
    "Self-Supervised Learning": {
      "Contrastive": [
        "wav2vec 2.0",
        "WavLM"
      ],
      "Masked Prediction": [
        "HuBERT",
        "data2vec"
      ],
      "Multi-task": [
        "W2v-BERT",
        "ctaguchi/w2v-bert-2.0-gui",
        "abidanoaman/urdu-asr-xlsr53-finetuned"
      ]
    },
    "Tasks": {
      "Transcription": [
        "Real-time",
        "Offline",
        "Long-form"
      ],
      "Multilingual": [
        "Code-switching",
        "Low-resource",
        "Cross-lingual",
        "DewiBrynJones/whisper-large-v2-ft-cy-2601",
        "afaqalinagra/whisper-base-ps"
      ],
      "Multimodal": [
        "Audio-Visual ASR",
        "Speech Translation",
        "CLAP-Based Recognition"
      ],
      "Specialized": [
        "Medical Transcription",
        "Meeting Transcription",
        "Call Center",
        "Disordered Speech Recognition (Aphasia, Impaired Speech)",
        "Word Naming Recognition"
      ]
    },
    "Datasets": {
      "English": [
        "LibriSpeech",
        "Common Voice",
        "GigaSpeech",
        "SPGISpeech"
      ],
      "Multilingual": [
        "MLS",
        "FLEURS",
        "CoVoST",
        "VoxPopuli",
        "Pashto Common Voice (Scale Analysis)",
        "Akan Impaired Speech Dataset"
      ],
      "Benchmarks": [
        "ESB",
        "Open ASR Leaderboard"
      ]
    },
    "Techniques": {
      "Data Augmentation": [
        "SpecAugment",
        "Speed Perturbation",
        "Noise Injection"
      ],
      "Decoding": [
        "Beam Search",
        "CTC Decoding",
        "Language Model Fusion"
      ],
      "Compression": [
        "Quantization",
        "Distillation",
        "Pruning"
      ],
      "Adaptation": [
        "Depth-Aware Adaptation",
        "Low-Rank Adaptation (LoRA)",
        "Fine-tuning"
      ]
    },
    "Evaluation": {
      "Metrics": [
        "WER",
        "CER",
        "RTF",
        "BLEU (for ST)"
      ],
      "Benchmarks": [
        "Open ASR Leaderboard",
        "ESB",
        "SUPERB"
      ]
    },
    "Applications": {
      "Voice Assistants": [],
      "Accessibility": [
        "Captioning",
        "Hearing Aid",
        "Aphasia Support Tools"
      ],
      "Content Creation": [
        "Podcasting",
        "Subtitling"
      ],
      "Enterprise": [
        "Call Analytics",
        "Meeting Notes"
      ]
    }
  },
  "Speech Language Models": {
    "Architectures": {
      "Encoder-Decoder SLMs": [
        "AudioPaLM",
        "SpeechGPT",
        "LauraGPT"
      ],
      "Decoder-only SLMs": [
        "GSLM",
        "Spirit-LM",
        "Moshi",
        "VoxtLM"
      ],
      "Codec-based": [
        "VALL-E",
        "SoundStorm",
        "MusicGen"
      ]
    },
    "Speech Tokenization": {
      "Semantic Tokens": [
        "HuBERT k-means",
        "SpeechTokenizer",
        "WavTokenizer"
      ],
      "Acoustic Tokens": [
        "EnCodec",
        "SoundStream",
        "DAC",
        "Vocos"
      ],
      "Hybrid Approaches": [
        "Multi-codebook tokenization",
        "Semantic-acoustic fusion"
      ]
    },
    "Text-to-Speech": {
      "Autoregressive TTS": [
        "VALL-E",
        "SPEAR-TTS",
        "CLaM-TTS"
      ],
      "Non-autoregressive TTS": [
        "VITS",
        "NaturalSpeech",
        "Matcha-TTS"
      ],
      "Diffusion-based TTS": [
        "Grad-TTS",
        "DiffSinger"
      ]
    },
    "Speech Generation Tasks": {
      "Voice Cloning": [
        "Zero-shot voice cloning",
        "Few-shot adaptation"
      ],
      "Voice Conversion": [
        "Any-to-any VC",
        "Cross-lingual VC"
      ],
      "Speech-to-Speech": [
        "Direct translation",
        "Speech continuation",
        "Spoken dialogue"
      ],
      "Expressive Speech": [
        "Emotion control",
        "Prosody transfer",
        "Style transfer"
      ]
    },
    "Training Approaches": {
      "Pre-training": [
        "Speech-text joint pre-training",
        "Next-token prediction on speech",
        "Masked speech modeling"
      ],
      "Alignment": [
        "Speech-text alignment",
        "Interleaved speech-text training"
      ],
      "Reinforcement Learning": [
        "RLHF for speech",
        "DPO for speech quality"
      ]
    },
    "Evaluation": {
      "Metrics": [
        "MOS (Mean Opinion Score)",
        "PESQ",
        "UTMOS",
        "Speaker similarity",
        "Word Error Rate"
      ],
      "Benchmarks": [
        "SUPERB",
        "Dynamic-SUPERB",
        "AudioBench"
      ]
    }
  }
}
