# ASR & Speech Language Daily Update — 2026-02-27

## Summary

The most significant development today is the introduction of TADA, a generative framework that addresses the sequence length bottleneck in speech LLMs by employing a text-acoustic dual alignment approach to replace traditional fixed-frame-rate tokenization. Concurrent research emphasizes a major push for robust long-form processing in low-resource contexts, particularly through two independent holistic frameworks for Bengali ASR and speaker diarization that utilize extreme augmentation and CTC-based alignment. New model releases continue to be dominated by domain-specific fine-tuning of Whisper—targeting languages like Marathi and Yoruba—alongside specialized encoders like wav2vec2 for singing phoneme recognition. Together, these papers signal an emerging trend toward modular, mixture-of-expert architectures for multimodal tasks and more efficient, dialect-aware modeling for endangered languages.

## New Papers (5)


| Title | Authors | Category | Link |
|-------|---------|----------|------|
| A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations | Soumya Dutta, Smruthi Balaji, Sriram Ganapathy | cs.CL | [arXiv](https://arxiv.org/abs/2602.23300v1) |
| Make It Hard to Hear, Easy to Learn: Long-Form Bengali ASR and Speaker Diarization via Extreme Augmentation and Perfect Alignment | Sanjid Hasan, Risalat Labib, A H M Fuad et al. | cs.SD | [arXiv](https://arxiv.org/abs/2602.23070v1) |
| TADA: A Generative Framework for Speech Modeling via Text-Acoustic Dual Alignment | Trung Dang, Sharath Rao, Ananya Gupta et al. | cs.SD | [arXiv](https://arxiv.org/abs/2602.23068v1) |
| A Holistic Framework for Robust Bangla ASR and Speaker Diarization with Optimized VAD and CTC Alignment | Zarif Ishmam, Zarif Mahir, Shafnan Wasif et al. | cs.SD | [arXiv](https://arxiv.org/abs/2602.22935v1) |
| Efficient Dialect-Aware Modeling and Conditioning for Low-Resource Taiwanese Hakka Speech Processing | An-Ci Peng, Kuan-Tang Huang, Tien-Hong Lo et al. | cs.CL | [arXiv](https://arxiv.org/abs/2602.22522v1) |


## New Models & Datasets (52)


| Name | Architecture | Key Innovation | Link |
|------|-------------|----------------|------|
| smkrv/whisper-podlodka-turbo-coreml | — | — | [HF](https://huggingface.co/smkrv/whisper-podlodka-turbo-coreml) |
| AWARRITech/whisper-small-yoruba-v1 | — | — | [HF](https://huggingface.co/AWARRITech/whisper-small-yoruba-v1) |
| fiendshadow/whisper-large-v3 | — | — | [HF](https://huggingface.co/fiendshadow/whisper-large-v3) |
| lyonlu13/wav2vec2-large-zh-singing-phoneme-ctc | — | — | [HF](https://huggingface.co/lyonlu13/wav2vec2-large-zh-singing-phoneme-ctc) |
| geexmmo/whisper-tiny.en-ONNX | — | — | [HF](https://huggingface.co/geexmmo/whisper-tiny.en-ONNX) |
| vivekb29/whisper-small-30-report-sentences | — | — | [HF](https://huggingface.co/vivekb29/whisper-small-30-report-sentences) |
| lewiswoncy/m_test_9_98 | — | — | [HF](https://huggingface.co/lewiswoncy/m_test_9_98) |
| Prasad12344321/whisper-Marathi-small-finetuned | — | — | [HF](https://huggingface.co/Prasad12344321/whisper-Marathi-small-finetuned) |
| wasimlhr/whisper-quran-phase1-step4500 | — | — | [HF](https://huggingface.co/wasimlhr/whisper-quran-phase1-step4500) |
| larimb/w2v-bert-2.0-ccv-kaggle-v1 | — | — | [HF](https://huggingface.co/larimb/w2v-bert-2.0-ccv-kaggle-v1) |
| GJATT/xls-r-2b-punjabi-finetuned_20songs | — | — | [HF](https://huggingface.co/GJATT/xls-r-2b-punjabi-finetuned_20songs) |
| TigreGotico/parakeet-tdt_ctc-110m-coreml | — | — | [HF](https://huggingface.co/TigreGotico/parakeet-tdt_ctc-110m-coreml) |
| ahmadrgul/mujawwad-v1 | — | — | [HF](https://huggingface.co/ahmadrgul/mujawwad-v1) |
| dianavdavidson/wh_l_v3_turbo_iv_no_lang_id_indic_voices_49414_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_turbo_iv_no_lang_id_indic_voices_49414_trial) |
| dianavdavidson/wh_l_v3_iv_no_lang_id_indic_voices_49414_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_iv_no_lang_id_indic_voices_49414_trial) |
| dianavdavidson/audiox_iv_no_lang_id_indic_voices_49398_trial | — | — | [HF](https://huggingface.co/dianavdavidson/audiox_iv_no_lang_id_indic_voices_49398_trial) |
| dianavdavidson/audiox_iv_no_lang_id_indic_voices_49393_trial | — | — | [HF](https://huggingface.co/dianavdavidson/audiox_iv_no_lang_id_indic_voices_49393_trial) |
| dianavdavidson/audiox_fleurs_no_lang_id_fleurs_49398_trial | — | — | [HF](https://huggingface.co/dianavdavidson/audiox_fleurs_no_lang_id_fleurs_49398_trial) |
| dianavdavidson/wh_l_v3_iv_no_lang_id_indic_voices_49392_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_iv_no_lang_id_indic_voices_49392_trial) |
| dianavdavidson/wh_medium_iv_no_lang_id_indic_voices_49389_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_medium_iv_no_lang_id_indic_voices_49389_trial) |
| dianavdavidson/wh_small_iv_no_lang_id_indic_voices_49389_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_small_iv_no_lang_id_indic_voices_49389_trial) |
| RedHatAI/nemotron-speech-streaming-en-0.6b | — | — | [HF](https://huggingface.co/RedHatAI/nemotron-speech-streaming-en-0.6b) |
| RedHatAI/Voxtral-Mini-4B-Realtime-2602 | — | — | [HF](https://huggingface.co/RedHatAI/Voxtral-Mini-4B-Realtime-2602) |
| dianavdavidson/seamless-m4t_v2_iv_no_lang_id_indic_voices_49371_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless-m4t_v2_iv_no_lang_id_indic_voices_49371_trial) |
| dianavdavidson/seamless-m4t_v2_iv_indic_voices_49370_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless-m4t_v2_iv_indic_voices_49370_trial) |
| dianavdavidson/seamless_m4t_v2_cv_no_lang_id_common_voices_49371_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless_m4t_v2_cv_no_lang_id_common_voices_49371_trial) |
| dianavdavidson/seamless-m4t_v2_mucs_no_lang_id_mucs_49371_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless-m4t_v2_mucs_no_lang_id_mucs_49371_trial) |
| dianavdavidson/seamless_m4t_v2_fleurs_no_lang_id_fleurs_49371_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless_m4t_v2_fleurs_no_lang_id_fleurs_49371_trial) |
| dianavdavidson/seamless_m4t_v2_fleurs_fleurs_49370_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless_m4t_v2_fleurs_fleurs_49370_trial) |
| speaklar/speaklar_stt_bn_fastconformer | — | — | [HF](https://huggingface.co/speaklar/speaklar_stt_bn_fastconformer) |
| lewiswoncy/m_test_9_99 | — | — | [HF](https://huggingface.co/lewiswoncy/m_test_9_99) |
| weiren119/Qwen3-ASR-1.7B-CoreML | — | — | [HF](https://huggingface.co/weiren119/Qwen3-ASR-1.7B-CoreML) |
| dianavdavidson/seamless_m4t_v2_mucs_mucs_49308_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless_m4t_v2_mucs_mucs_49308_trial) |
| wageehkhad/whisper-medium-finetuned-sada-asr | — | — | [HF](https://huggingface.co/wageehkhad/whisper-medium-finetuned-sada-asr) |
| 7ocho/WMCA1-S2 | — | — | [HF](https://huggingface.co/7ocho/WMCA1-S2) |
| dianavdavidson/seamless_m4t_v2_cv_common_voices_49267_trial | — | — | [HF](https://huggingface.co/dianavdavidson/seamless_m4t_v2_cv_common_voices_49267_trial) |
| weepower/CustomASRModel | — | — | [HF](https://huggingface.co/weepower/CustomASRModel) |
| lewiswoncy/m_test_9_3 | — | — | [HF](https://huggingface.co/lewiswoncy/m_test_9_3) |
| vysakh25/whisper-tiny-ki-edge | — | — | [HF](https://huggingface.co/vysakh25/whisper-tiny-ki-edge) |
| dianavdavidson/audiox_mucs_mucs_49234_trial | — | — | [HF](https://huggingface.co/dianavdavidson/audiox_mucs_mucs_49234_trial) |
| lewiswoncy/m_test_9_1 | — | — | [HF](https://huggingface.co/lewiswoncy/m_test_9_1) |
| dianavdavidson/audiox_cv_common_voices_49226_trial | — | — | [HF](https://huggingface.co/dianavdavidson/audiox_cv_common_voices_49226_trial) |
| dianavdavidson/wh_medium_cv_common_voices_49223_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_medium_cv_common_voices_49223_trial) |
| dianavdavidson/wh_small_cv_common_voices_49223_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_small_cv_common_voices_49223_trial) |
| Eimhin03/irish-whisper-combined-aug_attempt3old | — | — | [HF](https://huggingface.co/Eimhin03/irish-whisper-combined-aug_attempt3old) |
| daksh-neo/MOSS-TTS | — | — | [HF](https://huggingface.co/daksh-neo/MOSS-TTS) |
| beleata74/bg-tts-v7 | — | — | [HF](https://huggingface.co/beleata74/bg-tts-v7) |
| diskrot/bark-diskrot | — | — | [HF](https://huggingface.co/diskrot/bark-diskrot) |
| chilakavyshnavi/XTTS-v2 | — | — | [HF](https://huggingface.co/chilakavyshnavi/XTTS-v2) |
| iBoostAI/Demucs-v4 | — | — | [HF](https://huggingface.co/iBoostAI/Demucs-v4) |
| Varij179/yashil | — | — | [HF](https://huggingface.co/Varij179/yashil) |
| raditotev/bg-audiobooks-tts | — | raditotev | [HF](https://huggingface.co/datasets/raditotev/bg-audiobooks-tts) |




## Key Ideas


- A Mixture-of-Experts architecture called MiSTER-E effectively integrates temporal speech and text features to capture emotional flow in multi-turn conversations.

- Extreme data augmentation and precise alignment techniques facilitate the development of robust joint ASR and speaker diarization models for long-form audio in low-resource languages.

- The TADA framework improves speech generation efficiency by replacing traditional fixed-frame-rate acoustic tokenization with a dual text-acoustic alignment approach that reduces sequence length.

- Optimized Voice Activity Detection combined with CTC-based alignment significantly enhances the stability and accuracy of ASR and diarization for audio segments exceeding sixty seconds.

- Dialect-aware conditioning and multi-script modeling enable ASR systems to handle high dialectal variability and dual writing systems in endangered languages like Taiwanese Hakka.
