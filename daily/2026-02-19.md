# ASR Daily Update — 2026-02-19

## Summary

The release of **ZeroSyl** marks a significant advancement in Generative Spoken Language Modeling (GSLM) by introducing a zero-resource syllable tokenization method that effectively mitigates the sequence length explosion inherent in frame-level discrete SSL units. This work addresses a critical bottleneck in training speech-only LMs, enabling better modeling of long-range dependencies without relying on phonetic or textual transcripts. On the model front, the proliferation of fine-tuned **MMS-1B** checkpoints for low-resource languages and the introduction of the **Voxtral-Mini-3B** series signal a strong trend toward democratizing high-performance, multilingual speech-text integration at an accessible scale. Collectively, these developments highlight an industry-wide push to optimize the trade-off between acoustic temporal resolution and linguistic density in unified speech-centric architectures.

## New Papers (1)


| Title | Authors | Category | Link |
|-------|---------|----------|------|
| ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling | Nicol Visser, Simon Malan, Danel Slabbert et al. | cs.CL | [arXiv](https://arxiv.org/abs/2602.15537v1) |


## New Models & Datasets (74)


| Name | Architecture | Key Innovation | Link |
|------|-------------|----------------|------|
| 9DTechnologies/wav2vec2_v1 | — | — | [HF](https://huggingface.co/9DTechnologies/wav2vec2_v1) |
| vitthalbhandari/mms-1b-all-aft-all-cgg | — | — | [HF](https://huggingface.co/vitthalbhandari/mms-1b-all-aft-all-cgg) |
| Aayush9029/voxtral-mini-3b-4bit-mixed | — | — | [HF](https://huggingface.co/Aayush9029/voxtral-mini-3b-4bit-mixed) |
| Aayush9029/voxtral-mini-3b-8bit | — | — | [HF](https://huggingface.co/Aayush9029/voxtral-mini-3b-8bit) |
| Aayush9029/Voxtral-Mini-3B-2507 | — | — | [HF](https://huggingface.co/Aayush9029/Voxtral-Mini-3B-2507) |
| vitthalbhandari/mms-1b-all-aft-all-bxk | — | — | [HF](https://huggingface.co/vitthalbhandari/mms-1b-all-aft-all-bxk) |
| vitthalbhandari/mms-1b-all-aft-all-bew | — | — | [HF](https://huggingface.co/vitthalbhandari/mms-1b-all-aft-all-bew) |
| vitthalbhandari/mms-1b-all-aft-all-aln | — | — | [HF](https://huggingface.co/vitthalbhandari/mms-1b-all-aft-all-aln) |
| larimb/w2v-bert-2.0-ptbr | — | — | [HF](https://huggingface.co/larimb/w2v-bert-2.0-ptbr) |
| Kush0610/whisper-small-hi-uncurated-baseline-low-lr | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-baseline-low-lr) |
| Kush0610/whisper-small-hi-uncurated-baseline-high-lr | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-baseline-high-lr) |
| saidaAo/wav2vec2-base-librispeech-demo | — | — | [HF](https://huggingface.co/saidaAo/wav2vec2-base-librispeech-demo) |
| dianavdavidson/wh_l_v3_mucs_no_langid_mucs_48419_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_mucs_no_langid_mucs_48419_trial) |
| dianavdavidson/wh_medium_mucs_no_langid_mucs_48419_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_medium_mucs_no_langid_mucs_48419_trial) |
| dianavdavidson/wh_l_v3_turbo_mucs_no_langid_mucs_48419_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_turbo_mucs_no_langid_mucs_48419_trial) |
| dianavdavidson/wh_small_mucs_no_langid_mucs_48419_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_small_mucs_no_langid_mucs_48419_trial) |
| MinaNasser/whisper-base-arabic-mightyds | — | — | [HF](https://huggingface.co/MinaNasser/whisper-base-arabic-mightyds) |
| Professor/mms-300m-fongbe | — | — | [HF](https://huggingface.co/Professor/mms-300m-fongbe) |
| MathildeB3/52Hz-small-fr-v2b | — | — | [HF](https://huggingface.co/MathildeB3/52Hz-small-fr-v2b) |
| zacdan4801/wav2vec2-large-xlsr-53-ipa | — | — | [HF](https://huggingface.co/zacdan4801/wav2vec2-large-xlsr-53-ipa) |
| dianavdavidson/wh_l_v3_mucs_mucs_48363_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_mucs_mucs_48363_trial) |
| dianavdavidson/wh_l_v3_turbo_mucs_mucs_48363_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_l_v3_turbo_mucs_mucs_48363_trial) |
| dianavdavidson/wh_medium_mucs_mucs_48363_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_medium_mucs_mucs_48363_trial) |
| dianavdavidson/wh_small_mucs_mucs_48356_trial | — | — | [HF](https://huggingface.co/dianavdavidson/wh_small_mucs_mucs_48356_trial) |
| DanaRL/whisper-large-v3-zw-ar-180226 | — | — | [HF](https://huggingface.co/DanaRL/whisper-large-v3-zw-ar-180226) |
| Kush0610/whisper-medium-hi-uncurated-reverse-mft-1-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-medium-hi-uncurated-reverse-mft-1-1-1) |
| csikasote/mms-1b-all-bemgen-combined-sd-0.0 | — | — | [HF](https://huggingface.co/csikasote/mms-1b-all-bemgen-combined-sd-0.0) |
| Eimhin03/output_model_whisper_base_shunya_data_augmentation_enabled | — | — | [HF](https://huggingface.co/Eimhin03/output_model_whisper_base_shunya_data_augmentation_enabled) |
| Evolverocks/whisperkit-coreml | — | — | [HF](https://huggingface.co/Evolverocks/whisperkit-coreml) |
| Kush0610/whisper-medium-hi-uncurated-mft-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-medium-hi-uncurated-mft-1-1) |
| Kush0610/whisper-medium-hi-uncurated-reverse-mft-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-medium-hi-uncurated-reverse-mft-1-1) |
| Janchan123/whisperkit-coreml | — | — | [HF](https://huggingface.co/Janchan123/whisperkit-coreml) |
| maxkulish/parakeet-tdt-0.6b-v3 | — | — | [HF](https://huggingface.co/maxkulish/parakeet-tdt-0.6b-v3) |
| 15luna/whisper-small-finetuned | — | — | [HF](https://huggingface.co/15luna/whisper-small-finetuned) |
| 15luna/whisper-small-lora-merged | — | — | [HF](https://huggingface.co/15luna/whisper-small-lora-merged) |
| ghananlpcommunity/w2v-bert-2.0_twi_alpha_v1 | — | — | [HF](https://huggingface.co/ghananlpcommunity/w2v-bert-2.0_twi_alpha_v1) |
| Kush0610/whisper-small-hi-uncurated-reverse-mft-1-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-reverse-mft-1-1-1) |
| Kush0610/whisper-small-hi-uncurated-mft-1-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-mft-1-1-1) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_8e-6 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_8e-6) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.4e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.4e-5) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.2e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.2e-5) |
| Kush0610/whisper-medium-hi-uncurated-mft-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-medium-hi-uncurated-mft-1) |
| Kush0610/whisper-small-hi-uncurated-reverse-mft-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-reverse-mft-1-1) |
| Kush0610/whisper-small-hi-uncurated-mft-1-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-mft-1-1) |
| MinaNasser/whisper-small-arabic | — | — | [HF](https://huggingface.co/MinaNasser/whisper-small-arabic) |
| Kush0610/whisper-medium-hi-uncurated-reverse-mft-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-medium-hi-uncurated-reverse-mft-1) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.6e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.6e-5) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_6e-6 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_6e-6) |
| Kush0610/whisper-small-hi-uncurated-mft-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-mft-1) |
| corygong/stt_en_conformer_ctc_small | — | — | [HF](https://huggingface.co/corygong/stt_en_conformer_ctc_small) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.8e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.8e-5) |
| Kush0610/whisper-small-hi-uncurated-reverse-mft-1 | — | — | [HF](https://huggingface.co/Kush0610/whisper-small-hi-uncurated-reverse-mft-1) |
| MaddoggProduction/whisper-l-v3-turbo-quran-lora-dataset-mix | — | — | [HF](https://huggingface.co/MaddoggProduction/whisper-l-v3-turbo-quran-lora-dataset-mix) |
| Tmanna/whisper-bengali-final | — | — | [HF](https://huggingface.co/Tmanna/whisper-bengali-final) |
| abidanoaman/urdu-asr-xlsr53-finetuned | — | — | [HF](https://huggingface.co/abidanoaman/urdu-asr-xlsr53-finetuned) |
| ishtiakmoin/tugstugi-whisper-medium-bengali-finetuned-1 | — | — | [HF](https://huggingface.co/ishtiakmoin/tugstugi-whisper-medium-bengali-finetuned-1) |
| Eimhin03/output_model_base_Eubookshop_pretrained_shunya | — | — | [HF](https://huggingface.co/Eimhin03/output_model_base_Eubookshop_pretrained_shunya) |
| csikasote/mms-1b-all-bemgen-combined-gdro-new | — | — | [HF](https://huggingface.co/csikasote/mms-1b-all-bemgen-combined-gdro-new) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.0e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.0e-5) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.8e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.8e-5) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.6e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.6e-5) |
| IsGarrido/Whisper-Medicalv1 | — | — | [HF](https://huggingface.co/IsGarrido/Whisper-Medicalv1) |
| csikasote/mms-1b-all-bemgen-combined-gdro | — | — | [HF](https://huggingface.co/csikasote/mms-1b-all-bemgen-combined-gdro) |
| hamza-amin/urdu-mms-checkpoint | — | — | [HF](https://huggingface.co/hamza-amin/urdu-mms-checkpoint) |
| stcoats/whisper-large-v3-DASS2019-ct2 | — | — | [HF](https://huggingface.co/stcoats/whisper-large-v3-DASS2019-ct2) |
| csikasote/mms-1b-all-bemgen-combined-vanilla | — | — | [HF](https://huggingface.co/csikasote/mms-1b-all-bemgen-combined-vanilla) |
| csikasote/mms-1b-all-bemgen-combined-sd | — | — | [HF](https://huggingface.co/csikasote/mms-1b-all-bemgen-combined-sd) |
| wandererupak/whisper-small-n-demo-final-augmented-new-data-X | — | — | [HF](https://huggingface.co/wandererupak/whisper-small-n-demo-final-augmented-new-data-X) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.2e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_1.2e-5) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.0e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.0e-5) |
| nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.4e-5 | — | — | [HF](https://huggingface.co/nkkbr/whisper-large-v3-zatoichi-ja-JDG_ver_20260217_lr_2.4e-5) |
| wandererupak/whisper-small-n-demo-ultimate-train-Z | — | — | [HF](https://huggingface.co/wandererupak/whisper-small-n-demo-ultimate-train-Z) |
| wandererupak/whisper-small-n-demo-ultimate-train-XX | — | — | [HF](https://huggingface.co/wandererupak/whisper-small-n-demo-ultimate-train-XX) |
| wandererupak/whisper-small-n-demo-ultimate-train-Y | — | — | [HF](https://huggingface.co/wandererupak/whisper-small-n-demo-ultimate-train-Y) |




## Key Ideas


- ZeroSyl introduces a zero-resource syllable tokenization method that eliminates the need for textual supervision or phoneme labels in pure speech language modeling.

- The approach addresses the excessive sequence length of self-supervised speech tokens by condensing frame-level features into denser, syllable-like units.

- This simplified tokenization strategy improves the training efficiency of spoken language models while preserving the phonetic and rhythmic nuances of the original audio.

- By operating independently of text, ZeroSyl facilitates the creation of high-performance speech-to-speech models for unwritten or low-resource languages.

- The researchers demonstrate that simple, unsupervised syllable discovery can achieve parity with more complex and computationally expensive tokenization frameworks.
